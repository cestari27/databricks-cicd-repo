name: CI Pipeline for Azure Databricks

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install Databricks CLI
        run: pip install databricks-cli

      - name: Configure Databricks CLI
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = $DATABRICKS_HOST" >> ~/.databrickscfg
          echo "token = $DATABRICKS_TOKEN" >> ~/.databrickscfg
          chmod 600 ~/.databrickscfg

      - name: Upload to Workspace instead of DBFS
        run: |
          databricks workspace mkdirs /Shared/cicd-data || true
          databricks workspace import sample_sales.csv /Shared/cicd-data/sample_sales.csv --language TEXT --overwrite

      - name: Verify upload
        run: databricks workspace ls /Shared/cicd-data/
